{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6emEWnHI-78w"
   },
   "outputs": [],
   "source": [
    "# κάνουμε update τις βιβλιοθήκες μας\n",
    "!pip install -U scikit-learn\n",
    "!pip install --upgrade pandas\n",
    "!pip install -U scipy\n",
    "!pip install --upgrade numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NO_qd5W7N4pX"
   },
   "source": [
    "# Αξιολόγηση ταξινόμησης με ακρίβεια, ανάκληση και F1, μέσοι όροι\n",
    "Η πιστότητα είναι μια πολύ χρήσιμη και πρακτική μετρική της απόδοσης ενός ταξινομητή. Ωστόσο, δεν αρκεί για μια ολκοληρωμένη μελέτη της απόδοσής του. Είναι τυπικό για όλα τα προβλήματα machine learning να χρησιμοποιούμε διαφορετικές μετρικές για να μελετήσουμε τις ιδιότητες των δεδομένων. \n",
    "\n",
    "Καταρχάς, ας ξαναφέρουμε το Iris dataset και τον kNN και ας κάνουμε προβλέψεις με τον default kNN (είναι ακριβώς ο κώδικας από το προηγούμενο notebook σε ένα cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M7S5oMasoiux"
   },
   "outputs": [],
   "source": [
    "# Load Iris and organize our data\n",
    "from sklearn.datasets import load_iris\n",
    "data = load_iris()\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']\n",
    "# Χρησιμοποιούμε τη γνωστή train_test_split για να διαχωρίσουμε σε train και test set\n",
    "# το (int) όρισμα \"random_state\" είναι το seed της γεννήτριας τυχαίων αριθμών (αν του δώσουμε τιμή θα παράξει την ίδια σειρά τυχαίων αριθμών)\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.40, random_state=78)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Swg5-nF2pbsx"
   },
   "source": [
    "Η βάση για τις μετρικές απόδοσης των ταξινομητών είναι ο πίνακας σύγχυσης (confusion matrix). O πίνακας σύχγησης $C$  είναι τέτοιος ώστε το $C_{i, j}$ είναι ίσο με τα δείγματα που ενώ ανήκουν στην κατηγορία $i$ ταξινομήθηκαν στην κατηγορία  $j$. Για το Iris, στο συγκεκριμένο train/test split, o πίνακας σύγχυσης είναι:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 885,
     "status": "ok",
     "timestamp": 1573479932770,
     "user": {
      "displayName": "Γιώργος Αλεξανδρίδης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAHgjbkpnVZpMkbe7ihkb3km8rd5_Hm0fOfRa_yBg=s64",
      "userId": "16422904839632337525"
     },
     "user_tz": -120
    },
    "id": "mcMHwGmJN4pZ",
    "outputId": "ed4ecc03-13c2-44ec-9b3c-333cac43e89d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa' 'versicolor' 'virginica'] \n",
      "\n",
      "[[20  0  0]\n",
      " [ 0 22  1]\n",
      " [ 0  0 17]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test, pred)\n",
    "# τυπώνουμε τα labels\n",
    "print(label_names, \"\\n\")\n",
    "# τυπώνουμε το confusion matrix\n",
    "print(cnf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUP5FyOdN4pe"
   },
   "source": [
    "που σημαίνει ότι 1 δείγμα που άνηκε κανονικά στο είδος versicolor ταξινομήθηκε λανθασμένα στο είδος virginica. Τα στοιχεία της διαγωνίου είναι αληθινά θετικά δείγματα (true positive) της κάθε κλάσης. Για κάθε κλάση $i$ τα στοιχεία της γραμμής $i$ εκτός της διαγωνίου είναι λάνθασμένα αρνητικά δείγματα (false negative) της κλάσης και τα στοιχεία της κολώνας $i$ εκτός της διαγωνίου είναι λανθασμένα θετικά δείγματα (false positive) της κλάσης. \n",
    "\n",
    "\n",
    "<figure>\n",
    "  <center>\n",
    "  <img src=\"http://scikit-learn.org/stable/_images/sphx_glr_plot_confusion_matrix_001.png\" alt=\"Confusion Matrix\">\n",
    "   <figcaption>Confusion matrix στο Iris - αλλος ταξινομητής (SVM)</figcaption>\n",
    "  </center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Σε περίπτωση δυαδικού ταξινομητή $C_{0,0}$ είναι τα αληθινά αρνητικά δείγματα (true negative, η κλάση 0 θεωρείται η αρνητική), $C_{1,0}$ είναι τα λανθασμένα αρνητικά δείγματα, $C_{1,1}$ τα αληθινά θετικά δείγματα και $C_{0,1}$ τα λανθασμένα θετικά. Για παράδειγμα:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 665,
     "status": "ok",
     "timestamp": 1573479938451,
     "user": {
      "displayName": "Γιώργος Αλεξανδρίδης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAHgjbkpnVZpMkbe7ihkb3km8rd5_Hm0fOfRa_yBg=s64",
      "userId": "16422904839632337525"
     },
     "user_tz": -120
    },
    "id": "knmN5cfFN4pf",
    "outputId": "1ed37c81-38e8-450e-dae9-6d1d97dc1f61"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 2 1 1\n"
     ]
    }
   ],
   "source": [
    "# παράδειγμα confusion matrix σε δυαδική ταξινόμηση\n",
    "tn, fp, fn, tp = confusion_matrix([0, 1, 0, 1], [1, 1, 1, 0]).ravel()\n",
    "print(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L5YF7Z4BN4pi"
   },
   "source": [
    "Συχνά στην δυαδική ταξινόμηση θεωρούμε θετική την πιο σπάνια κλάση ή το φαινόμενο προς εντοπισμό (πχ διαβητικός). \n",
    "\n",
    "![CMMulti2](http://image.ntua.gr/~tpar/dataminingimg/confusionMatrix2small.PNG)\n",
    "\n",
    "Ορίζουμε:\n",
    "Ακρίβεια -Precision- ($P$) είναι ο λόγος των true positives ($T_p$) ως προς τον αριθμό των true positives συν τον αριθμό των false positives ($F_p$).\n",
    "$$P = \\frac{T_p}{T_p+F_p}$$\n",
    "Ανάκληση -Recall- ($R$) είναι ο λόγος των true positives ($T_p$) ως προς τον αριθμό των true positives συν τον αριθμό των false negatives ($F_n$).\n",
    "$$R = \\frac{T_p}{T_p + F_n}$$\n",
    "Συχνά χρησιμοποιούμε και το ($F_1$) score, το οποίο είναι ο αρμονικός μέσος της ακρίβειας και της ανάκλησης.\n",
    "$$F1 = 2\\frac{P \\times R}{P+R}$$\n",
    "Ιδανικά θέλουμε και υψηλή ακρίβεια και υψηλή ανάκληση, ωστόσο μεταξύ της ακρίβειας και της ανάκλησης υπάρχει γενικά trade-off. Στην οριακή περίπτωση του ταξινομητή που επιστρέφει σταθερά μόνο τη θετική κλάση για παράδειγμα, η ανάκληση θα είναι 1 αλλά η ακρίβεια θα έχει τη μικρότερη δυνατή τιμή της. Γενικά, κατεβάζοντας το κατώφλι της απόφασης του ταξινομητή, αυξάνουμε την ανάκληση και μειώνουμε την ακρίβεια και αντιστρόφως.\n",
    "\n",
    "Στην πράξη και ειδικά σε μη ισορροπημένα datasets χρησιμοποιούμε την ακρίβεια, ανάκληση και το F1 πιο συχνά από την πιστότητα. Επίσης, ανάλογα την εφαρμογή μπορεί να μας ενδιαφέρει περισσότερο ένα συγκεκριμένο metric, πχ η ανάκληση (πχ στη διάγνωση μιας ασθένειας) ή η ακρίβεια (πχ σε μια οικονομική απόφαση)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 793,
     "status": "ok",
     "timestamp": 1573479943094,
     "user": {
      "displayName": "Γιώργος Αλεξανδρίδης",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mAHgjbkpnVZpMkbe7ihkb3km8rd5_Hm0fOfRa_yBg=s64",
      "userId": "16422904839632337525"
     },
     "user_tz": -120
    },
    "id": "hbaie_yIN4pk",
    "outputId": "7ee17b3c-41ee-444c-ddf7-3fb3dbbec85f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([1.        , 1.        , 0.94444444]), array([1.        , 0.95652174, 1.        ]), array([1.        , 0.97777778, 0.97142857]), array([20, 23, 17])) \n",
      "\n",
      "(0.9833333333333333, 0.9833333333333333, 0.9833333333333333, None) \n",
      "\n",
      "(0.9814814814814815, 0.9855072463768115, 0.9830687830687831, None) \n",
      "\n",
      "(0.9842592592592593, 0.9833333333333333, 0.9833862433862434, None) \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        20\n",
      "  versicolor       1.00      0.96      0.98        23\n",
      "   virginica       0.94      1.00      0.97        17\n",
      "\n",
      "    accuracy                           0.98        60\n",
      "   macro avg       0.98      0.99      0.98        60\n",
      "weighted avg       0.98      0.98      0.98        60\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "# εκτυπώνουμε 4 πίνακες, precision, recall, F1 και support. Support είναι ο συνολικός αριθμός προβλέψεων σε κάθε κλάση\n",
    "# το πρώτο στοιχείο του κάθε πίνακα είναι η κλάση setosa, το δεύτερο η versicolor και το τρίτο η virginica\n",
    "print(precision_recall_fscore_support(y_test, pred, average=None), \"\\n\")\n",
    "\n",
    "# εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας υπόψη συνολικά (αθροίζοντας εκτός κλάσεων) τα δείγματα (average = micro).\n",
    "print(precision_recall_fscore_support(y_test, pred, average='micro'), \"\\n\")\n",
    "\n",
    "# εκτυπώνουμε το μέσο όρο των precision, recall και F1 θεωρόντας ότι οι κλάσεις έχουν το ίδιο βάρος (average = macro)\n",
    "print(precision_recall_fscore_support(y_test, pred, average='macro'), \"\\n\")\n",
    "\n",
    "# εκτυπώνουμε τa precision, recall και F1 λαμβάνοντας. Με average = weighted κάθε κλάση μετρά στο μέσο όρο ανάλογα με το support της.\n",
    "print(precision_recall_fscore_support(y_test, pred, average='weighted'), \"\\n\")\n",
    "\n",
    "# η classification_report τυπώνει πιο ωραία οπτικά σε string τα αποτελέσματα\n",
    "# πρώτα για κάθε κλάση και μετά με μέσους όρους\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, pred, target_names=label_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3NgAbLr4ZhSB"
   },
   "source": [
    "Documentation από το scikit σχετικά με την αξιολόγηση των μοντέλων:\n",
    "\n",
    "* [sklearn.metrics.precision_recall_fscore_support](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_recall_fscore_support.html)\n",
    "* [Model evaluation: quantifying the quality of predictions](http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification)\n",
    "* [Multiclass and multilabel classification](http://scikit-learn.org/stable/modules/model_evaluation.html#multiclass-and-multilabel-classification)\n",
    "\n",
    "Σημειώστε ότι όταν η classification report μέχρι το version 0.19 του scikit τυπώνει μόνο ένα μέσο όρο, τον weighted. (σχετική συζήτηση [εδώ](https://stackoverflow.com/questions/23914472/strange-f1-score-result-using-scikit-learn))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yD1gabVouubh"
   },
   "source": [
    "# Άσκηση: Σύγκριση του Gausian Naive Bayes και του kNN στo Pima Indians Diabetes dataset\n",
    "![1889 Photograph shows half-length portrait of two Pima Indians, facing front, wearing bead necklaces.](https://i.pinimg.com/236x/60/05/76/600576905d4ad5bb1a9c3e3387b397ca--pima-indians-native-american-indians.jpg \"1889 Photograph shows half-length portrait of two Pima Indians, facing front, wearing bead necklaces.\")\n",
    "\n",
    "Διαβάστε το [\"pima-indians-diabetes.data.csv\"](https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv) σε ένα numpy array data και ξεχωρίστε features και labels.\n",
    "\n",
    "Για 40% test set: \n",
    "1. υπολογίστε την πρόβλεψη του Gaussian Naive Bayes με τη μέθοδο predict(). \n",
    "2. πάρτε τις προβλέψεις ενός kNN με k=5\n",
    "3. Για έναν ταξινομητή kNN, με 3-fold cross validation και με μετρική 'f1_weighted' υπολογίστε το βέλτιστο k στο train set (maximum k=50). \n",
    "4. εκτυπώστε με την \"classification_report\" τα precision, recall, f1, support για τον NB, τον kNN με k=5 και με το k που έχει προκύψει από cross validation.\n",
    "5. Κάντε 3 runs και αποθηκεύστε σε ένα κελί markdown το average F1 του non optimized και του optimized kNN. Πόσο % έχει βελτιβωθεί η επίδοσή του; \n",
    "\n",
    "hint: Για τη δημιουργία πινάκων σε markdown μπορείτε να χρησιμοποιείτε ένα [markdown table generator](https://www.tablesgenerator.com/markdown_tables)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "2.0 Classification.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
