{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MZLbuyvjNC53"
   },
   "source": [
    "# Εισαγωγή scikit-learn και dataset στο notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoIlBu68NC54"
   },
   "source": [
    "Αρχικά κάνουμε upgrade στις βιβλοθήκες που θα χρειαστούμε, αν δεν έχουμε ήδη κάνει. \n",
    "* Το επόμενο cell είναι για Google Colaboratory και Microsoft Azure. \n",
    "* Στο Kaggle πρέπει πρώτα να ενεργοποιήσετε τη [σύνδεση internet](https://storage.googleapis.com/kaggle-media/forum/internet_setting.png) ώστε να μπορεί το pip να κατεβάζει πακέτα. Ακολουθήστε τις οδηγίες (θα σας ζητήσει επαλήθευση με sms pin)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 218
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 17431,
     "status": "ok",
     "timestamp": 1572938383453,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "wVeTFMhlNC55",
    "outputId": "21e5dea2-90c9-4e1f-db02-d54b9380ca08",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
      "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.21.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.17.3)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.0)\n",
      "Requirement already up-to-date: numpy in /usr/local/lib/python3.6/dist-packages (1.17.3)\n",
      "Requirement already up-to-date: pandas in /usr/local/lib/python3.6/dist-packages (0.25.3)\n",
      "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.17.3)\n",
      "Requirement already satisfied, skipping upgrade: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.6.1)\n",
      "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip #upgrade pip package installer\n",
    "!pip install scikit-learn --upgrade #upgrade scikit-learn package\n",
    "!pip install numpy --upgrade #upgrade numpy package\n",
    "!pip install pandas --upgrade #--upgrade #upgrade pandas package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HtGvRuQMNC5_"
   },
   "source": [
    "![UCI ML Logo](http://archive.ics.uci.edu/ml/assets/logo.gif \"UCI Machine Learning Repository\")\n",
    "\n",
    "To [UCI ML Repository](http://archive.ics.uci.edu/ml/index.php) είναι το διασημότερο αποθετήριο datasets για Machine Learning. Το dataset με το οποίο θα δουλέψουμε είναι το [Breast Cancer Wisconsin Diagnostic Database](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29). Το dataset περιλαμβάνει διάφορες πληροφορίες για όγκους σχετιζόμενους με τον καρκίνο του στήθους καθώς και ετικέτες για κάθε δείγμα (sample), αν το δείγμα αντιστοιχεί σε καλοήθη όγκο ή κακοήθη. Το σύνολο δεδομένων έχει 569 δείγματα για αντίστοιχους όγκους και περιλαμβάνει 30 χαρακτηριστικά (attributes) για κάθε δείγμα, όπως ακτίνα του όγκου, υφή, ομοιομορφία και περιοχή. Θα χρησιμοποιήσουμε αυτό το dataset και τα χαρακτηριστικά για να προβλέψουμε αν ένας όγκος είναι κακοήθης ή όχι.\n",
    "\n",
    "Το Scikit-learn έχει για κάποια datasets, μεταξύ των οποίων και το breast cancer, έτοιμες συναρτήσεις για να τα φορτώνουμε χωρίς να χρειαστεί να διαβάσουμε text file. Τα datasets αποτελούν τα toy datasets του scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZocYkGPENC6A"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Load dataset\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "u67rXHqANC6D"
   },
   "source": [
    "Η μεταβλητή \"data\" είναι ένα αντικείμενο Python που δουλεύει σαν dictionary.\n",
    "\n",
    "| **key**              | **value**                                             | **type**     | **size**   |\n",
    "| :------------------- | :---------------------------------------------------- | :----------- | :--------- |\n",
    "| **'DESCR'**          | 'Breast Cancer Wisconsin (Diagnostic) Database...'    | str          |  1         | \n",
    "| **'data'**           | [[1.799, 1.038, 1.228,...]...]                        | float array  |  (569,30)  | \n",
    "| **'feature_names'**  | ['mean radius', 'mean texture', ...]                  | str array    | (30,)      |\n",
    "| **'target'**         | [0, 0, 0, ..., 0, 0, 1]                               | int array    | (569,)     |\n",
    "| **'target_names'**   | ['malignant', 'benign']                               | str array    | (2,)       |\n",
    "\n",
    "Τα σημαντικά κλειδιά του λεξικού είναι οι ονομασίες των κατηγοριών εξόδου (target_names), οι κατηγορίες (ή κλάσεις ή ετικέτες) εξόδου (target), τα ονόματα των χαρακτηριστικών (feature_names) και τέλος τα ίδια τα χαρακτηριστικά (data). Στην πράξη χρειαζόμαστε μόνο τα χαρακτηριστικά (features) και τις ετικέτες τους (labels). Οι ονομασίες μας πληροφορούν για τη φυσική ερμηνεία των χαρακτηριστικών.\n",
    "\n",
    "Δημιουργούμε νέες μεταβλητές για κάθε σημαντικό σύνολο πληροφορίας του dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rjctATtVNC6E"
   },
   "outputs": [],
   "source": [
    "# Organize our data\n",
    "label_names = data['target_names']\n",
    "labels = data['target']\n",
    "feature_names = data['feature_names']\n",
    "features = data['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1421,
     "status": "ok",
     "timestamp": 1572939013938,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "du2g0h6tNC6G",
    "outputId": "981771d5-1662-40c2-9ea6-387d6da84d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# ποιες είναι οι κατηγορίες (ετικέτες) μας\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 891,
     "status": "ok",
     "timestamp": 1572939031060,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "yHURhwN6NC6K",
    "outputId": "b50514a0-4241-4117-be32-a3e2aeb85a8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "(569,)\n",
      "frequencies: [212 357]\n"
     ]
    }
   ],
   "source": [
    "# οι κατηγορίες όλων των 569 δειγμάτων 0: κακοήθης - malignant (Μ) 1: καλοήθης - benign (Β)\n",
    "print(labels)\n",
    "# οι κατηγορίες είναι ένα μονοδιάστατο array\n",
    "print(labels.shape)\n",
    "# μετράμε τη συχνότητα των δύο κλάσεων\n",
    "import numpy as np\n",
    "print(\"frequencies:\", np.bincount(labels))\n",
    "# Class distribution: 357 benign, 212 malignant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 887,
     "status": "ok",
     "timestamp": 1572939093306,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "dvIQ-oKgNC6M",
    "outputId": "e001eecb-2f26-45db-af0b-cec7e9a25baf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# η κατηγορία του πρώτου δείγματος\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MMwrGyN-T5Tr"
   },
   "source": [
    "Εφόσον το 0 είναι κακοήθης και το 1 καλοήθης, το πρώτο δείγμα αντιπροσωπεύει έναν κακοήθη όγκο."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 182
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 930,
     "status": "ok",
     "timestamp": 1572939102865,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "oZhaPsQkNC6Q",
    "outputId": "e220090d-3d63-492d-fd95-93b4c63914e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    }
   ],
   "source": [
    "# τα ονόματα των χαρακτηριστικών (features)\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1049,
     "status": "ok",
     "timestamp": 1572939105505,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "jkQ1sjkUNC6U",
    "outputId": "ed0f9d4d-16a5-4403-ab13-13d36f261638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean radius\n"
     ]
    }
   ],
   "source": [
    "# το όνομα του πρώτου χαρακτηριστικού\n",
    "print(feature_names[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MBlOkCq-2thc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 925,
     "status": "ok",
     "timestamp": 1572939127715,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "c3y1smBANC6X",
    "outputId": "a6d6a0f5-eb47-4950-8581-3ccd95a0316c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n"
     ]
    }
   ],
   "source": [
    "# οι διαστάσεις όλων των χαρακτηριστικών\n",
    "# τα χαρακτηριστικά του πρώτου δείγματος (κακοήθες)\n",
    "print(features.shape)\n",
    "print(features[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QVEyDtLzNC6a"
   },
   "source": [
    "Στο συγκεκριμένο παράδειγμα λοιπόν, τo πρώτο δείγμα μας είναι κακοήθες με ακτίνα του όγκου  1.79900000e+01."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5yWY1o4A1QaJ"
   },
   "source": [
    "# Ασκηση 1\n",
    "\n",
    "## Toy dataset #2: \"Wine\"\n",
    "\n",
    "1. Εισάγετε τη συνάρτηση \"load_wine\" και αποθηκεύστε τα δεδομένα στο αντικείμενο data_2.\n",
    "2. Οργανώστε τα δεδομένα σας στους πίνακες label_names_2, labels_2, feature_names_2, features_2 (Προσοχή στα ονόματα για να μην κάνετε overwrite τους πίνακες τους wisconsin)\n",
    "\n",
    "\n",
    "* Ποιά είναι τα ονόματα των χαρακτηριστικών;\n",
    "* Ποιές και πόσες είναι οι κατηγορίες των δειγμάτων;\n",
    "* Πόσα είναι τα δείγματα;\n",
    "* Ποιό είναι η τιμή της στάχτης (ash) του 10ου δείγματος;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZScX_Zpd_-4l"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data2 = load_wine()\n",
    "label_names2 = data2['target_names']\n",
    "labels2 = data2['target']\n",
    "feature_names2 = data2['feature_names']\n",
    "features2 = data2['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 110
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1033,
     "status": "ok",
     "timestamp": 1572939186898,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "yhKmI2SEZ9k7",
    "outputId": "e53953f5-2e00-4ee3-f5d0-c3fc9ac1d1b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium', 'total_phenols', 'flavanoids', 'nonflavanoid_phenols', 'proanthocyanins', 'color_intensity', 'hue', 'od280/od315_of_diluted_wines', 'proline']\n",
      "['class_0' 'class_1' 'class_2'] (3,)\n",
      "178\n",
      "2.27\n"
     ]
    }
   ],
   "source": [
    "print(feature_names2)\n",
    "print(label_names2, hlabel_names2.sape)\n",
    "print(feurates2.shape[0])\n",
    "print(features2[9][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hf5MPEWN-kcW"
   },
   "source": [
    "Έχουμε φορτώσει το wisconsin breast cancer dataset, θα προχωρήσουμε στο να δημιουργήσουμε απλούς ταξινομητές για να προβλέπουμε αν οι όγκοι είναι καλοήθεις ή κακοήθεις."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZBZBRvfDNC6c"
   },
   "source": [
    "# Train set, test set & αξιολόγηση (ορθότητα) ταξινομητών"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "I5K4xNQMNC6d"
   },
   "source": [
    "Η αξιολόγηση των ταξινομητών γίνεται πάντα σε δεδομένα που δεν έχουν δει κατά την εκπαίδευση έτσι ώστε να αξιολογήσουμε τη δυνατότητα γενίκευσής τους. Συνεπώς, πρωτού φτιάξουμε το μοντέλο κάθε ταξινομητή χωρίζουμε τα δεδομένα μας τυχαία σε ένα σύνολο εκπαίδευσης (train set) και ένα σύνολο ελέγχου (test set).\n",
    "Παρακάτω βλέπουμε ένα παράδειγμα διαχωρισμού του dataset με αναλογία 60-40:\n",
    "\n",
    "![data split](https://i.ibb.co/x3V1FQ4/train-test.png)\n",
    "\n",
    "Χρησιμοποιούμε το train set για να εκτιμούμε και να βελτιώνουμε το μοντέλο του ταξινομητή κατά την ανάπτυξή του. Δεν επιτρέπεται σε κανένα σημείο η χρήση των δεδομένων test για την εκπαίδευση του ταξινομητή.\n",
    "\n",
    "![training](https://i.ibb.co/MMWjVkn/training.png)\n",
    "\n",
    "Χρησιμοποιούμε μετά το test set για να αξιολογήσουμε στατιστικά την απόδοση του μοντέλου μας.\n",
    "\n",
    "![testing](https://i.ibb.co/JsSDLpX/testing.png)\n",
    "\n",
    "Το sklearn έχει τη συνάρτηση train_test_split() που ανακατεύει τυχαία τα δείγματα και τα διαχωρίζει σε train και test με βάση κάποιο ποσοστό που θα της δώσουμε."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_6FSK_hNC6e"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split our data\n",
    "train, test, train_labels, test_labels = train_test_split(features, labels, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XAe7U6rNNC6g"
   },
   "source": [
    "Θα δοκιμάσουμε πρώτα κάποιες πολύ απλές τακτικές ταξινόμησης. Η κλάση DummyClassifier δέχεται μια παράμετρο που καθορίζει την τακτική της ταξινόμησης ως εξής:\n",
    "* “uniform”: προβλέπει τυχαία και ομοιόμορφα.\n",
    "* “constant”: προβλέπει πάντα μία κατηγορία που τη διαλέγει ο χρήστης.\n",
    "* “most_frequent”: προβλέπει πάντα την πιο συχνή κατηγορία στο training set.\n",
    "* “stratified”: κάνει προβλέψεις διατηρώντας την κατανομή των κλάσεων στο training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 127
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1428,
     "status": "ok",
     "timestamp": 1572939721947,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "vaLmfZkZNC6h",
    "outputId": "45e6ae15-555c-4a77-e0c3-71c97c6ea651"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 0 1 1 1 1 1 1 0 1 0 1 0 1 0 1 0 1 1 1 1 1 1 1 1 0 0 0 0 1 1 0 0 0 1\n",
      " 0 0 1 0 1 1 1 1 0 1 0 0 0 1 1 1 0 0 0 0 0 1 1 0 0 0 0 1 0 1 0 0 1 0 0 0 0\n",
      " 1 0 1 0 0 1 0 0 1 0 1 1 0 1 0 1 1 1 1 1 1 0 0 0 0 1 0 1 1 0 1 0 1 1 1 1 0\n",
      " 0 1 1 1 0 1 0 1 1 0 0 1 0 1 0 0 1 0 1 0 1 1 0 0 0 1 1 1 1 1 1 1 0 1 1 0 0\n",
      " 1 1 1 1 1 1 0 1 1 0 1 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 0 0 0 1 1 0 0 0 1 0 0\n",
      " 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "dc_uniform = DummyClassifier(strategy=\"uniform\")\n",
    "dc_constant_0 = DummyClassifier(strategy=\"constant\", constant=0)\n",
    "dc_constant_1 = DummyClassifier(strategy=\"constant\", constant=1)\n",
    "dc_most_frequent = DummyClassifier(strategy=\"most_frequent\")\n",
    "dc_stratified = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "#με τη μέθοδο fit \"εκπαιδεύουμε\" τον ταξινομητή στο σύνολο εκπαίδευσης (τα χαρακτηριστικά και τις ετικέτες τους)\n",
    "model = dc_uniform.fit(train, train_labels)\n",
    "\n",
    "#με τη μέθοδο predict παράγουμε προβλέψεις για τα δεδομένα ελέγχου (είσοδος τα χαρακτηριστικά μόνο)\n",
    "preds = dc_uniform.predict(test)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UVXonGNONC6k"
   },
   "source": [
    "Για την αξιολόγηση, το πιο απλό κριτήριο είναι να συγκρίνουμε το ποσοστό ομοιότητας των πίνακων preds και test_labels. Το κριτήριο αυτό ονομάζεται ορθότητα (accuracy). Αν το κάναμε manually, για κάθε στοιχείο (δείγμα) των πινάκων που είναι όμοιο (0 και 0 ή 1 και 1) αυξάνουμε έναν μετρητή. Στην περίπτωση που είναι ανόμοια δεν τον αυξάνουμε. Διαιρούμε την τελική τιμή του μετρητή με το πλήθος των στοιχείων του πίνακα.\n",
    "Το προηγούμενο for loop μας το δίνει έτοιμο η συνάρτηση accuracy_score:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 816,
     "status": "ok",
     "timestamp": 1572939782553,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "cHKESBEKNC6l",
    "outputId": "cd16df11-6147-4592-8f3c-2cb477e71da4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5053191489361702\n",
      "0.5372340425531915\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(test_labels, preds))\n",
    "\n",
    "# ο υπολογισμός του accuracy είναι επίσης -ακόμα πιο βολικά- και μέθοδος του αντικειμένου dummy classifier\n",
    "print(dc_uniform.score(test, test_labels)) # σε κάθε κλήση της dc_uniform έχουμε ξανά τυχαίες προβλέψεις"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "BKM-YNvqNC6o"
   },
   "source": [
    "Παρατηρούμε ότι αν τρέξουμε το πρoηγούμενο κελί διαδοχικές φορές, το δεύτερο accuracy αλλάζει γιατί καλούμε εκ νέου τον ταξινομητή να κάνει (τυχαίες) προβλέψεις.\n",
    "\n",
    "Ας αποθηκεύσουμε την ορθότητα όλων των dummy classifiers σε ένα λεξικό και να την τυπώσουμε από την καλύτερη στη χειρότερη"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 863,
     "status": "ok",
     "timestamp": 1572939892186,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "ZS1PyAOzNC6p",
    "outputId": "b995fd3e-4a42-43e5-95a5-7b5f2771a692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy on the Wisconsin Breast Cancer Dataset (33% test set)\n",
      "\n",
      "constant 1 0.6063829787234043\n",
      "most frequent label 0.6063829787234043\n",
      "stratified 0.5106382978723404\n",
      "uniform (random) 0.4787234042553192\n",
      "constant 0 0.39361702127659576\n"
     ]
    }
   ],
   "source": [
    "wisconsin_accuracy = {}\n",
    "wisconsin_accuracy['uniform (random)'] = dc_uniform.score(test, test_labels)\n",
    "model = dc_constant_0.fit(train, train_labels)\n",
    "wisconsin_accuracy['constant 0'] = dc_constant_0.score(test, test_labels)\n",
    "model = dc_constant_1.fit(train, train_labels)\n",
    "wisconsin_accuracy['constant 1'] = dc_constant_1.score(test, test_labels)\n",
    "model = dc_most_frequent.fit(train, train_labels)\n",
    "wisconsin_accuracy['most frequent label'] = dc_most_frequent.score(test, test_labels)\n",
    "model = dc_stratified.fit(train, train_labels)\n",
    "wisconsin_accuracy['stratified'] = dc_stratified.score(test, test_labels)\n",
    "\n",
    "print(\"Classification Accuracy on the Wisconsin Breast Cancer Dataset (33% test set)\\n\")\n",
    "sorted_accuracy = [(k, wisconsin_accuracy[k]) for k in sorted(wisconsin_accuracy, key=wisconsin_accuracy.get, reverse=True)]\n",
    "for k, v in sorted_accuracy:\n",
    "  print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "tTIPdDYXNC6s"
   },
   "source": [
    "# Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8USxUnlANC6u"
   },
   "source": [
    "![$P(A\\mid B)={\\frac {P(B\\mid A)\\,P(A)}{P(B)}}$](https://upload.wikimedia.org/wikipedia/commons/thumb/1/18/Bayes%27_Theorem_MMB_01.jpg/220px-Bayes%27_Theorem_MMB_01.jpg \"A blue neon sign, showing the simple statement of Bayes’ theorem\")\n",
    "\n",
    "H βασική ιδέα λειτουργίας του ταξινομητή είναι α) ο γνωστός νόμος του Bayes $$P(A\\mid B)={\\frac {P(B\\mid A)\\,P(A)}{P(B)}}$$\n",
    "\n",
    "και β) η (naive) υπόθεση ότι τα χαρακτηριστικά είναι όλα ανεξάρτητα μεταξύ τους (δεν ισχύει γενικά, αλλά ο ταξινομητής είναι πρακτικά καλός σε πολλές περιπτώσεις). Παράδειγμα: θα βρέξει σήμερα? Naive Bayes: \"Θα το προβλέψω με βάση το παρελθόν θεωρώντας ότι τα χαρακτηριστικά θερμοκρασία, νεφοκάλυψη και ατμοσφαιρική πίεση είναι όλα ανεξάρτητα μεταξύ τους\".\n",
    "\n",
    "Με δεδομένα μια μεταβλητή κατηγορίας (κλάσης) $y$ και ένα εξαρτώμενο διάνυσμα χαρακτηριστικών $x_1$ μέχρι $x_n$, σύμφωνα με το θεώρημα του Bayes θα ισχύει \n",
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots x_n \\mid y)}{P(x_1, \\dots, x_n)}$$\n",
    "Ισχύει ότι $P(x_1, \\dots, x_i, \\dots, x_n \\mid y) =  \\prod_{i=1}^{n} P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n)$ και κάνουμε την αφελή υπόθεση ότι το χαρακτηριστικό $x_i$ για κάθε $i$ εξαρτάται μόνο από την κλάση $y$ και όχι από οποιοδήποτε άλλο χαρακτηριστικό\n",
    "$$P(x_i | y, x_1, \\dots, x_{i-1}, x_{i+1}, \\dots, x_n) = P(x_i | y)$$\n",
    "αυτό οδηγεί στην απλοποίηση\n",
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) \\prod_{i=1}^{n} P(x_i \\mid y)}{P(x_1, \\dots, x_n)}$$\n",
    "Με δεδομένη είσοδο, το $P(x_1, \\dots, x_n)$ είναι σταθερό. Συνεπώς μπορούμε να χρησιμοποιήσουμε τον ακόλουθο κανόνα ταξινόμησης $$P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)$$\n",
    "$$\\Downarrow$$\n",
    "$$\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y)$$\n",
    "Το $P(y)$ είναι η υπόθεσή μας και ισούται με τη σχετική συχνότητα της κλάσης $y$ στο training set. To $P(x_i \\mid y)$ είναι η πιθανοφάνεια δηλαδή η πιθανότητα του δείγματος με δεδομένη την υπόθεσή μας και μπορεί επίσης να υπολογιστεί απλά από το training set. Οι διάφοροι Naive Bayes classifiers διαφοροποιούνται κυρίως από τις υποθέσεις που κάνουν ως προς την κατανομή $P(x_i \\mid y)$. Η κλάση $\\hat{y}$ που ανατίθεται σε ένα νέο δείγμα είναι αυτή που μεγιστοποιεί το δεξί μέλος της σχέσης."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4_GNZAxxNC6u"
   },
   "source": [
    "## Ένα παράδειγμα NB με κατηγορικές μεταβλητές\n",
    "\n",
    "Έστω ότι για 14 μέρες παρατηρήσαμε 4 μεταβλητές του καιρού (νεφοκάλυψη, θερμοκρασία, υγρασία και άνεμο) και το αν τελικά παίξαμε τέννις. Τα χαρακτηριστικά μας είναι κατηγορικά, παίρνουν δηλαδή διακριτές τιμές από ενα ορισμένο σύνολο τιμών.\n",
    "\n",
    "| Day | Outlook  | Temperature | Humidity | Wind   | Play Tennis? |\n",
    "|-----|----------|-------------|----------|--------|--------------|\n",
    "| 1   | Sunny    | Hot         | High     | Weak   | No           |\n",
    "| 2   | Sunny    | Hot         | High     | Strong | No           |\n",
    "| 3   | Overcast | Hot         | High     | Weak   | Yes          |\n",
    "| 4   | Rain     | Mild        | High     | Weak   | Yes          |\n",
    "| 5   | Rain     | Cool        | Normal   | Weak   | Yes          |\n",
    "| 6   | Rain     | Cool        | Normal   | Strong | No           |\n",
    "| 7   | Overcast | Cool        | Normal   | Strong | Yes          |\n",
    "| 8   | Sunny    | Mild        | High     | Weak   | No           |\n",
    "| 9   | Sunny    | Cool        | Normal   | Weak   | Yes          |\n",
    "| 10  | Rain     | Mild        | Normal   | Weak   | Yes          |\n",
    "| 11  | Sunny    | Mild        | Normal   | Strong | Yes          |\n",
    "| 12  | Overcast | Mild        | High     | Strong | Yes          |\n",
    "| 13  | Overcast | Hot         | Normal   | Weak   | Yes          |\n",
    "| 14  | Rain     | Mild        | High     | Strong | No           |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tMoHXWhaNC6v"
   },
   "source": [
    "Το πρώτο βήμα είναι να γράψουμε 4 πίνακες αναφοράς (\"look-up tables\"), έναν για κάθε χαρακτηριστικό,  με την πιθανότητα να παιχτεί ή να μην παιχτεί τέννις σε σχέση με το χαρακτηριστικό. Έχουμε συνολικά 5 περιπτώσεις που δεν μπορέσαμε να παίξουμε και 9 που μπορέσαμε. Οι 4 πίνακες είναι οι ακόλουθοι:\n",
    "\n",
    "| OUTLOOK  | Play = Yes | Play = No | Total |\t| TEMPERATURE | Play = Yes | Play = No | Total |\t| HUMIDITY | Play = Yes | Play = No | Total |\t| WIND   | Play = Yes | Play = No | Total |\n",
    "|----------|------------|-----------|-------|\t|-------------|------------|-----------|-------|\t|----------|------------|-----------|-------|\t|--------|------------|-----------|-------|\n",
    "| Sunny    | 2/9        | 3/5       | 5/14  |\t| Hot         | 2/9        | 2/5       | 4/14  |\t| High     | 3/9        | 4/5       | 7/14  |\t| Strong | 3/9        | 3/5       | 6/14  |\n",
    "| Overcast | 4/9        | 0/5       | 4/14  |\t| Mild        | 4/9        | 2/5       | 6/14  |\t| Normal   | 6/9        | 1/5       | 7/14  |\t| Weak   | 6/9        | 2/5       | 8/14  |\n",
    "| Rain     | 3/9        | 2/5       | 5/14  |\t| Cool        | 3/9        | 1/5       | 4/14  |\t| Cool     | 3/9        | 1/5       | 4/14  |\t| Cool   | 3/9        | 1/5       | 4/14  |\n",
    "και τέλος υπολογίζουμε την πιθανότητα να παίξουμε και να μην παίξουμε:\n",
    "\n",
    "P(Play=Yes) = 9/14\n",
    "\n",
    "P(Play=No) = 5/14\n",
    "\n",
    "### Testing\n",
    "\n",
    "Έστω ένα νέο δείγμα X = (Outlook=Sunny, Temperature=Cool, Humidity=High, Wind=Strong). Σε ποια κατηγορία ανήκει; (θα παίξουμε τέννις ή όχι).\n",
    "\n",
    "Υπολογίζουμε πρώτα από τους πίνακες αναφοράς την \"πιθανότητα\" να παίξουμε\n",
    "\n",
    "* P(Outlook=Sunny | Play=Yes) = 2/9\n",
    "* P(Temperature=Cool | Play=Yes) = 3/9\n",
    "* P(Humidity=High | Play=Yes) = 3/9\n",
    "* P(Wind=Strong | Play=Yes) = 3/9\n",
    "* P(Play=Yes) = 9/14\n",
    "\n",
    "Σύμφωνα με τον κανόνα ταξινόμησης του NB η πιθανότητα να παίξουμε είναι ανάλογη του γινομένου των προηγούμενων \n",
    "\n",
    "P(X|Play=Yes)P(Play=Yes) = (2/9) \\* (3/9) \\* (3/9) \\* (3/9) \\* (9/14) = 0.0053\n",
    "\n",
    "Υπολογίζουμε παρόμοια την \"πιθανότητα\" να μην παίξουμε\n",
    "\n",
    "* P(Outlook=Sunny | Play=No) = 3/5\n",
    "* P(Temperature=Cool | Play=No) = 1/5\n",
    "* P(Humidity=High | Play=No) = 4/5\n",
    "* P(Wind=Strong | Play=No) = 3/5\n",
    "* P(Play=No) = 5/14\n",
    "\n",
    "P(X|Play=No)P(Play=No) = (3/5) \\* (1/5) \\* (4/5) \\* (3/5) \\* (5/14) = 0.0206\n",
    "\n",
    "Επειδή η ποσότητα 0.0206 είναι μεγαλύτερη από την 0.0053, η απόφαση του Naive Bayes είναι να μην παίξουμε τέννις. Οι ποσότητες αυτές (του αριθμητή) μας αρκούν για την απόφαση γιατί ο παρονομαστής είναι σταθερός. Για να πάρουμε τις πλήρεις πιθανότητες για το συγκεκριμένο δείγμα Χ υπολογίζουμε και τον παρονομαστή:\n",
    "\n",
    "* P(X) = P(Outlook=Sunny) \\* P(Temperature=Cool) \\* P(Humidity=High) \\* P(Wind=Strong)\n",
    "* P(X) = (5/14) \\* (4/14) \\* (7/14) \\* (6/14)\n",
    "* P(X) = 0.02186\n",
    "\n",
    "* P(Play=Yes | X) = 0.0053/0.02186 = 0.2424\n",
    "* P(Play=No | X) = 0.0206/0.02186 = 0.9421"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zqVEooVDNC6w"
   },
   "source": [
    "Θέλουμε να δοκιμάσουμε τον Naive Bayes στο Wisconsin. Εδώ όμως έχουμε συνεχείς μεταβλητές. Όπως είπαμε θα πρέπει να κάνουμε μια υπόθεση για την κατανομή $P(x_i \\mid y)$. Θα θεωρήσουμε ότι η κατανομή κάθε χαρακτηριστικού ως προς κάθε κλάση ακολουθεί την κανονική κατανομή:\n",
    "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$\n",
    "Ο συγκεκριμένος ταξινομητής είναι ο Gaussian Naive Bayes. Πρακτικά, με τα δεδομένα του training set, για κάθε κλάση υπολογίζουμε τη μέση τιμή $\\mu_y$ και τη διακύμανση $\\sigma^2_y$ κάθε χαρακτηριστικού για τη συγκεκριμένη κλάση. \n",
    "\n",
    "Ας δοκιμάσουμε τον Gaussian Naive Bayes στο Wisconsin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1421,
     "status": "ok",
     "timestamp": 1572940769366,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "7u7DytKBNC6x",
    "outputId": "53827226-b65e-470f-fe3b-3c7d19c322b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Accuracy on the Wisconsin Breast Cancer Dataset (33% test set)\n",
      "\n",
      "gaussian naive bayes 0.9202127659574468\n",
      "constant 1 0.6063829787234043\n",
      "most frequent label 0.6063829787234043\n",
      "stratified 0.5106382978723404\n",
      "uniform (random) 0.4787234042553192\n",
      "constant 0 0.39361702127659576\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "gnb = GaussianNB()\n",
    "# κάνουμε εκπαίδευση (fit) δηλαδή ουσιαστικά υπολογίζουμε μέση τιμή και διακύμανση για όλα τα χαρακτηριστικά και κλάσεις στο training set\n",
    "model = gnb.fit(train, train_labels)\n",
    "# η GaussianNB έχει builtin μέθοδο υπολογισμό accuracy. Αποθηκεύουμε την τιμή της στον πίνακά μας με τα αποτελέσματα από τα άλλα classifiers\n",
    "wisconsin_accuracy['gaussian naive bayes'] = gnb.score(test, test_labels)\n",
    "# και ξανατυπώνουμε τα sorted αποτελέσματα\n",
    "print(\"Classification Accuracy on the Wisconsin Breast Cancer Dataset (33% test set)\\n\")\n",
    "sorted_accuracy = [(k, wisconsin_accuracy[k]) for k in sorted(wisconsin_accuracy, key=wisconsin_accuracy.get, reverse=True)]\n",
    "for k, v in sorted_accuracy:\n",
    "  print(k,v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8xPMzJn6NC61"
   },
   "source": [
    "# Εισαγωγή dataset μέσω Pandas και CSV file\n",
    "\n",
    "To scikit learn έχει διαθέσιμο για φόρτωση απευθείας με συναρτήσεις μόνο ένα μικρό αριθμό datasets. Στη γενική περίπτωση, η τυπική διαδικασία για εισαγωγή datasets που θα συναντήσουμε είναι να διαβάζουμε ένα delimited text file (τιμές που διαχωρίζονται με ένα delimiter δλδ comma -Comma Separated Values, CSV-, semicolon etc) και να το αποθηκεύουμε σε πίνακες χαρακτηριστικών και ετικετών (class labels). \n",
    "\n",
    "Θα κάνουμε την προηγούμενη διαδικασία manually διαβάζοντας το breast cancer από text file. Η σελίδα του UCI για το breast cancer είναι [αυτή](https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+%28Diagnostic%29), και το dataset μπορούμε να το αποθηκεύσουμε locally στο Desktop απο το φάκελο \"Data Folder\" και το αρχείο [\"wdbc.data\"](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data). Το ανοίγουμε, δεξί κλικ και \"Save as\" (ή απευθείας \"Save link as\"). \n",
    "\n",
    "**ΠΡΟΣΟΧΗ: Ανάλογα το cloud οι διαδικασία εισαγωγής (και εξαγωγής) δεδομένων είναι διαφορετική.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5Cgmq3aXfhdN"
   },
   "source": [
    "## 1. Google Colaboratory\n",
    "\n",
    "Κάντε expand το αριστερό siebar, πηγαίνετε στο tab \"Files\" και στο UPLOAD διαλέγουμε το αρχείο \"wbcd.data\". Κάνουμε \"ΟΚ\" στο reminder ότι τα αρχεία θα διαγραφούν."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nl-J6kAxhQdA"
   },
   "source": [
    "Το αρχείο \"wdbc.data\" πρέπει να βρίσκεται στο file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18097,
     "status": "ok",
     "timestamp": 1572940938561,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "dF4rNf84hWdW",
    "outputId": "7a2f4cc6-501f-43ea-b719-0b93e2a03d36",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample_data  wdbc.data\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6FB_8hY11Qat"
   },
   "source": [
    "Εισάγουμε και διαβάζουμε το csv \"wdbc.data\" με την read_csv και option \"header=None\" γιατί η πρώτη γραμμή περιέχει δεδομένα και όχι ονόματα κολόνων και τυπώνουμε τις πρώτες πέντε γραμμές:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 444
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2351,
     "status": "ok",
     "timestamp": 1572941198591,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "_0C5rsqp1Qat",
    "outputId": "455d1a0f-b041-4937-9a5b-2cde9db17797"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>926424</td>\n",
       "      <td>M</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>926682</td>\n",
       "      <td>M</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>926954</td>\n",
       "      <td>M</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>927241</td>\n",
       "      <td>M</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>92751</td>\n",
       "      <td>B</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0  1      2      3   ...      28      29      30       31\n",
       "0      842302  M  17.99  10.38  ...  0.7119  0.2654  0.4601  0.11890\n",
       "1      842517  M  20.57  17.77  ...  0.2416  0.1860  0.2750  0.08902\n",
       "2    84300903  M  19.69  21.25  ...  0.4504  0.2430  0.3613  0.08758\n",
       "3    84348301  M  11.42  20.38  ...  0.6869  0.2575  0.6638  0.17300\n",
       "4    84358402  M  20.29  14.34  ...  0.4000  0.1625  0.2364  0.07678\n",
       "..        ... ..    ...    ...  ...     ...     ...     ...      ...\n",
       "564    926424  M  21.56  22.39  ...  0.4107  0.2216  0.2060  0.07115\n",
       "565    926682  M  20.13  28.25  ...  0.3215  0.1628  0.2572  0.06637\n",
       "566    926954  M  16.60  28.08  ...  0.3403  0.1418  0.2218  0.07820\n",
       "567    927241  M  20.60  29.33  ...  0.9387  0.2650  0.4087  0.12400\n",
       "568     92751  B   7.76  24.54  ...  0.0000  0.0000  0.2871  0.07039\n",
       "\n",
       "[569 rows x 32 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"wdbc.data\", header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRGrtYUb1Qaw"
   },
   "source": [
    "## 2. Microsoft Azure\n",
    "\n",
    "Ακολουθήστε αυτή τη διαδικασία για να εισάγετε δεδομένα από αρχείο CSV στο Microsof Azure:\n",
    "\n",
    "Εντός του project όπου βρίσκεται το notebook σας κάντε \"Upload\" -> \"From Computer\" -> \"Choose Files\" διαλέξτε το αρχείο για ανέβασμα (στην περίπτωσή μας το \"wdbc.data\") και κλικ \"Upload\". Το αρχείο θα είναι ορατό μέσα στο project από το notebook.\n",
    "\n",
    "Το αρχείο \"wdbc.data\" πρέπει να βρίσκεται στο file system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "89ZBf73u1Qax",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6SwCfCZ1Qa0"
   },
   "source": [
    "Εισάγουμε και διαβάζουμε το csv \"wdbc.data\" με την read_csv και option \"header=None\" γιατί η πρώτη γραμμή περιέχει δεδομένα και όχι ονόματα κολόνων και τυπώνουμε τις πρώτες πέντε γραμμές:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7o-5orhK1Qa1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"wdbc.data\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "h2AMxWYx1Qa3"
   },
   "source": [
    "## 3. Kaggle\n",
    "\n",
    "1. Διαλέξτε πάνω δεξιά \"Add Data\", μετά \"Upload\" και με \"Select Files to Upload\" (ή με drag'n'drop) ανεβάστε το αρχείο CSV (στην περίπτωσή μας το \"wdbc.data\"). \n",
    "2. Αριστερά, στο πεδίο \"Title\" εισάγετε τίτλο για το dataset. Βάλτε απλά \"wdbc.data\" (χωρίς τα εισαγωγικά) και πατήστε \"Create\".  Θα δημιουργηθεί ένα directory \"wdbc.data\" μέσα στο οποίο θα τοποθετηθεί το csv. (τυχόν κενά θα μετατραπούν σε minus sign, οι τελείες αφαιρούνται)\n",
    "3. Στην επόμενη οθόνη θα λάβουμε ειδοποίηση ότι το αρχείο αυτό είναι ήδη διαθέσιμο στο repository του Kaggle. Θα το αγνοήσουμε πατώντας \"Upload all files\". \n",
    "4. Στην τελευταία οθόνη πατήστε \"Confirm\".\n",
    "\n",
    "Το αρχείο CSV πρέπει να βρίσκεται στο file system, στο directory \"input\" εντός του directory που δημιουργήθηκε στο βήμα 2 και που είναι στο ίδιο ύψος με αυτό του notebook στο filesystem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qEP7pbb91Qa3"
   },
   "outputs": [],
   "source": [
    "!ls ../input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oROghpIp1Qa6"
   },
   "source": [
    "Εισάγουμε και διαβάζουμε το csv \"wdbc.data\" μέσα από το directory \"wdbcdata\" με την read_csv και option \"header=None\" γιατί η πρώτη γραμμή περιέχει δεδομένα και όχι ονόματα κολόνων και τυπώνουμε τις πρώτες πέντε γραμμές:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e3jmeZb_1Qa7"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../input/wdbcdata/wdbc.data\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Yuoy1EZa1Qa8"
   },
   "source": [
    "## 4. JetBrains Datalore\n",
    "\n",
    "1. Πηγαίνετε στο \"Tools\"->\"File Uploader\"\n",
    "2. Στο δεξί pane διαλέγετε \"Upload\" και διαλέγετε το αρχείο"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZbcfeHLb1Qa-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"wdbc.data\", header=None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BALr9Xoi1QbA"
   },
   "source": [
    "Αναλυτικές οδηγίες για upload δεδομένων στο IBM Watson Studio [εδώ](https://dataplatform.cloud.ibm.com/docs/content/analyze-data/load-and-access-data.html). Αναλυτικές οδηγίες για το IBM Cloud Object Storage και την Python [εδώ](https://dataplatform.cloud.ibm.com/docs/content/analyze-data/python_os.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMSwMFdB1QbA"
   },
   "source": [
    "# Μετατροπή δεδομένων σε numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MbrNcOcFNC64"
   },
   "source": [
    "Στο \"Data folder\" του UCI εκτός του \"wdbc.data.txt\" έχει και το [\"wdbc.names\"](https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.names) με τις ονομασίες των features. Έχουμε 32 attributes, το πρώτο είναι το ID του δείγματος, το δεύτερο η διάγνωση (\"Μ\" για malignant και \"B\" για benign) και τέλος 30 real-valued χαρακτηριστικά εισόδου. Θα αποθηκεύσουμε τη δεύτερη κολώνα (διάγνωση) σε ένα dataframe \"labels_df\" και τα αριθμητικά features σε ένα dataframe \"features_df\". Το sample ID στην πρώτη κολώνα δεν μας ενδιαφέρει. Ακολουθούμε πάντα τη διαδικασία του διαχωρισμού σε διαφορετικά dataframes όταν τα attributes είναι διαφορετικών data types (όπως εδώ που έχουμε string για την κλάση και float για τα υπόλοιπα χαρακτηριστικά), γιατί αλλιώς δυσκολεύει η μετατροπή σε numpy array που θα κάνουμε στη συνέχεια."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 383
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1613,
     "status": "ok",
     "timestamp": 1572941206005,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "1D6TgwjpNC65",
    "outputId": "287175c1-2d16-489a-d9f7-0819ea592d1b",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.799e+01 1.038e+01 1.228e+02 1.001e+03 1.184e-01 2.776e-01 3.001e-01\n",
      " 1.471e-01 2.419e-01 7.871e-02 1.095e+00 9.053e-01 8.589e+00 1.534e+02\n",
      " 6.399e-03 4.904e-02 5.373e-02 1.587e-02 3.003e-02 6.193e-03 2.538e+01\n",
      " 1.733e+01 1.846e+02 2.019e+03 1.622e-01 6.656e-01 7.119e-01 2.654e-01\n",
      " 4.601e-01 1.189e-01]\n",
      "(569, 30)\n",
      "False\n",
      "[[ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  2.77555756e-17\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00 -1.38777878e-17]\n",
      " ...\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 0.00000000e+00  0.00000000e+00  0.00000000e+00 ...  0.00000000e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "labels_df = df.iloc[:, [1]] # τα labels είναι στη δεύτερη κολώνα\n",
    "features_df = df.iloc[:, 2:] # τα features είναι όλες οι επόμενες κολονες\n",
    "# και δεν μας ενδιαφέρουν τα ids στην πρώτη\n",
    "\n",
    "# μετατρέπουμε το dataframe σε numpy array\n",
    "np_features = features_df.values\n",
    "\n",
    "print(np_features[0]) #τυπώνουμε το πρώτο δείγμα\n",
    "print(np_features.shape) #τυπώνουμε τις διαστάσεις του πίνακα των χαρακτηριστικών\n",
    "# επιβεβαιώνουμε ότι ο αρχικός πίνακας features ναι ίδιος με τον np_features\n",
    "print(np.array_equal(features, np_features))\n",
    "print(np_features - features)\n",
    "# είναι ίδιοι πρακτικά, απλά ο np_features έχει λίγο μεγαλύτερο precision "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6JiB5LnqNC68"
   },
   "source": [
    "Στο dataframe - κολώνα με τις κλάσεις \"labels_df\" πρέπει να μετατρέψουμε τα string 'M' και 'Β' σε 0 και 1 αντίστοιχα. Ορίζουμε ένα mapping και εφαρμόζουμε τη μέθοδο replace με το συγκεκριμένο mapping. \n",
    "\n",
    "Τέλος, αν εφαρμόσουμε μόνο τη μέθοδο \"values\" στο \"labels_df\" θα πάρουμε ένα np array δύο διαστάσεων (569, 1), ενώ θέλουμε να είναι μονοδιάστατος (569,). Για το λόγο αυτό εφαρμόζουμε επιπρόσθετα τη μέθοδο flatten(). Επιβεβαιώνουμε ότι ο αρχικός πίνακας labels είναι ίδιος με τον np_labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 346
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8837,
     "status": "ok",
     "timestamp": 1572941341779,
     "user": {
      "displayName": "Tasos Papagiannis",
      "photoUrl": "",
      "userId": "12080300236693277095"
     },
     "user_tz": -120
    },
    "id": "XVpk3OM_NC68",
    "outputId": "f53f514f-c200-4881-a363-b9e48ef14b76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 1 1 1 1 1 0 0 1 0 0 1 1 1 1 0 1 0 0 1 1 1 1 0 1 0 0\n",
      " 1 0 1 0 0 1 1 1 0 0 1 0 0 0 1 1 1 0 1 1 0 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1 1\n",
      " 1 1 1 1 1 1 0 0 0 1 0 0 1 1 1 0 0 1 0 1 0 0 1 0 0 1 1 0 1 1 0 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 0 1 0 1 1 0 0 1 1 0 0 1 1 1 1 0 1 1 0 0 0 1 0\n",
      " 1 0 1 1 1 0 1 1 0 0 1 0 0 0 0 1 0 0 0 1 0 1 0 1 1 0 1 0 0 0 0 1 1 0 0 1 1\n",
      " 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 1 1 0 0 0 1 1\n",
      " 1 1 0 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 0 1 0 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 0 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1\n",
      " 1 0 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 0 1 1 1 1 1 0 1 1\n",
      " 0 1 0 1 1 0 1 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 0 1 1 0 1 0 1 0 0\n",
      " 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1]\n",
      "(569,)\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "mapping = {'M': 0, 'B': 1}\n",
    "labels_df = labels_df.replace(mapping)\n",
    "# μετατρέπουμε το dataframe σε μονοδιάστατο array\n",
    "np_labels = labels_df.values.flatten()\n",
    "\n",
    "# επιβεβαιώνουμε ότι ο αρχικός πίνακας labels είναι ίδιος με τον np_labels\n",
    "print(np_labels)\n",
    "print(np_labels.shape)\n",
    "print(np.array_equal(labels, np_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxSiUEvtnADe"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "1.1 Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
